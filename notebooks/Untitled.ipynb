{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e29dc2b5-1821-42a5-8016-871d4e308f28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlalchemy in c:\\users\\91702\\anaconda3\\lib\\site-packages (2.0.34)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\91702\\anaconda3\\lib\\site-packages (from sqlalchemy) (4.11.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\91702\\anaconda3\\lib\\site-packages (from sqlalchemy) (3.0.1)\n",
      "Inserted 206529 rows into begin_inventory\n",
      "Inserted 224489 rows into end_inventory\n",
      "Inserted 300000 rows into purchases\n",
      "Inserted 300000 rows into purchases\n",
      "Inserted 300000 rows into purchases\n",
      "Inserted 300000 rows into purchases\n",
      "Inserted 300000 rows into purchases\n",
      "Inserted 300000 rows into purchases\n",
      "Inserted 300000 rows into purchases\n",
      "Inserted 272474 rows into purchases\n",
      "Inserted 12261 rows into purchase_prices\n",
      "Inserted 300000 rows into sales\n",
      "Inserted 300000 rows into sales\n",
      "Inserted 300000 rows into sales\n",
      "Inserted 300000 rows into sales\n",
      "Inserted 300000 rows into sales\n",
      "Inserted 300000 rows into sales\n",
      "Inserted 300000 rows into sales\n",
      "Inserted 300000 rows into sales\n",
      "Inserted 300000 rows into sales\n",
      "Inserted 300000 rows into sales\n",
      "Inserted 300000 rows into sales\n",
      "Inserted 300000 rows into sales\n",
      "Inserted 300000 rows into sales\n",
      "Inserted 300000 rows into sales\n",
      "Inserted 300000 rows into sales\n",
      "Inserted 300000 rows into sales\n",
      "Inserted 300000 rows into sales\n",
      "Inserted 300000 rows into sales\n",
      "Inserted 300000 rows into sales\n",
      "Inserted 300000 rows into sales\n",
      "Inserted 300000 rows into sales\n",
      "Inserted 300000 rows into sales\n",
      "Inserted 300000 rows into sales\n",
      "Inserted 300000 rows into sales\n",
      "Inserted 300000 rows into sales\n",
      "Inserted 300000 rows into sales\n",
      "Inserted 300000 rows into sales\n",
      "Inserted 300000 rows into sales\n",
      "Inserted 300000 rows into sales\n",
      "Inserted 300000 rows into sales\n",
      "Inserted 300000 rows into sales\n",
      "Inserted 300000 rows into sales\n",
      "Inserted 300000 rows into sales\n",
      "Inserted 300000 rows into sales\n",
      "Inserted 300000 rows into sales\n",
      "Inserted 300000 rows into sales\n",
      "Inserted 300000 rows into sales\n",
      "Inserted 300000 rows into sales\n",
      "Inserted 300000 rows into sales\n",
      "Inserted 300000 rows into sales\n",
      "Inserted 300000 rows into sales\n",
      "Inserted 300000 rows into sales\n",
      "Inserted 225363 rows into sales\n",
      "Inserted 5543 rows into vendor_invoice\n"
     ]
    }
   ],
   "source": [
    "!pip install sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd \n",
    "import os \n",
    "import time\n",
    "import logging\n",
    "\n",
    "# Basic logging setup\n",
    "logging.basicConfig(\n",
    "    filename=\"logs/inventory.log\",\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    filemode=\"a\"\n",
    ")\n",
    "engine = create_engine(\"mysql+pymysql://root:Banty&2003@localhost:3306/inventory\")\n",
    "\n",
    "def ingest_db(file_path, table_name, engine, chunk_size=300000):\n",
    "    \"Reads CSV in chunks and uploads to MySQL\"\n",
    "    for chunk in pd.read_csv(file_path, chunksize=chunk_size):\n",
    "        chunk.to_sql(table_name, con=engine, if_exists='append', index=False)\n",
    "        print(f\"Inserted {len(chunk)} rows into {table_name}\")\n",
    "\n",
    "# Loop through all files in folder\n",
    "\n",
    "\n",
    "\n",
    "def load_raw_data():\n",
    "    start = time.time()\n",
    "    \n",
    "    for file in os.listdir('data'):\n",
    "        if file.endswith('.csv'):\n",
    "            file_path = os.path.join('data', file)\n",
    "            table_name = file[:-4]  # remove .csv extension\n",
    "            logging.info(f\"Ingesting {file} into db\")\n",
    "            ingest_db(file_path, table_name, engine)\n",
    "    \n",
    "    end = time.time()\n",
    "    total_time = (end - start) / 60\n",
    "    logging.info('Ingestion complete')\n",
    "    logging.info(f\"Total time taken: {total_time:.2f} minutes\")\n",
    "\n",
    "\n",
    "if __name__ =='__main__':\n",
    "    load_raw_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e998983-8773-49d8-8d54-7ed5d6798d2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
